{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from model import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def split_data(data_set, train_percent, val_percent, test_percent):\n",
    "    data_set = data_set.shuffle(buffer_size=len(data_set), reshuffle_each_iteration=False)\n",
    "\n",
    "    train_size = int(len(data_set) * train_percent)\n",
    "    val_size = int(len(data_set) * val_percent)\n",
    "    test_size = int(len(data_set) * test_percent)\n",
    "\n",
    "    train_ds = data_set.take(train_size)\n",
    "    val_ds = data_set.skip(train_size).take(val_size)\n",
    "    test_ds = data_set.skip(train_size + val_size).take(test_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def prepare_using_layers(ds, directory_name=\"augmented_dataset\", rot=False, bright=False, flip=False):\n",
    "    \"\"\"\n",
    "    Function creates an augmented dataset from a given dataset using Sequential model layers\n",
    "    :param directory_name: name of a directory where augmented images will be saved\n",
    "    :param ds: dataset to be augmented\n",
    "    :param rot: determines whether to apply random rotation\n",
    "    :param bright: determines whether to apply random brightness\n",
    "    :param flip: determines whether to apply random flips\n",
    "    :return: augmented dataset\n",
    "    \"\"\"\n",
    "    batch, _ = next(iter(ds))\n",
    "    batch_size = batch.shape[0]\n",
    "    img_height = batch.shape[1]\n",
    "    img_width = batch.shape[2]\n",
    "\n",
    "    if not os.path.exists('datasets/' + directory_name):\n",
    "        os.makedirs('datasets/' + directory_name)\n",
    "    # labels = ds.class_names\n",
    "    labels = ['one', 'two', 'three', 'four', 'five']\n",
    "    for label in labels:\n",
    "        if not os.path.exists(f'datasets/{directory_name}/{label}'):\n",
    "            os.makedirs(f'datasets/{directory_name}/{label}')\n",
    "    counter = 0\n",
    "    for image_batch, labels_batch in ds:\n",
    "        for image, label in zip(image_batch, labels_batch):\n",
    "            tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "            counter += 1\n",
    "    if rot:\n",
    "        random_rot = tf.keras.Sequential([\n",
    "            layers.RandomRotation(0.2),\n",
    "        ])\n",
    "        augmented_ds = ds.map(lambda x, y: (random_rot(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        for image_batch, labels_batch in augmented_ds:\n",
    "            for image, label in zip(image_batch, labels_batch):\n",
    "                tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "                counter += 1\n",
    "    if bright:\n",
    "        random_bright = tf.keras.layers.RandomBrightness(factor=0.2)\n",
    "        augmented_ds = ds.map(lambda x, y: (random_bright(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        for image_batch, labels_batch in augmented_ds:\n",
    "            for image, label in zip(image_batch, labels_batch):\n",
    "                tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "                counter += 1\n",
    "    if flip:\n",
    "        random_flip = tf.keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        ])\n",
    "        augmented_ds = ds.map(lambda x, y: (random_flip(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        for image_batch, labels_batch in augmented_ds:\n",
    "            for image, label in zip(image_batch, labels_batch):\n",
    "                tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "                counter += 1\n",
    "\n",
    "    data_dir = 'datasets/' + directory_name\n",
    "    data = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        image_size=(img_height, img_width))\n",
    "\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3312 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"datasets/improved_gestures_dataset\"  # Remember to recreate or change the path to the actual dataset\n",
    "data_dir = path\n",
    "\n",
    "batch_size = 32\n",
    "# (Mystyk) Image size might be different, just a guess based on webcam repo\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width))\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "Found 4 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# augmented_ds = prepare(data, shuffle=False, rot=True , rgb=True, brightness=False, saturation=True, hue=False)\n",
    "augmented_ds = prepare_using_layers(data, directory_name=\"gestures_dataset\", rot=True, bright=True, flip=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13248\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for image_batch, labels_batch in augmented_ds:\n",
    "    for image, label in zip(image_batch, labels_batch):\n",
    "        counter += 1\n",
    "print(counter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = split_data(augmented_ds, 0.70, 0.2, 0.1)\n",
    "\n",
    "class_names = data.class_names\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1. / 255)\n",
    "\n",
    "num_classes = len(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "functions = [create_model1, create_model2, create_model3, create_model4, create_model5]\n",
    "filters = [8, 16, 32]\n",
    "dense_units = [32, 64, 128, 256]\n",
    "counter = 1\n",
    "total = len(filters) * len(dense_units) * len(functions)\n",
    "eval_results = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_10 (Rescaling)    (None, 300, 300, 3)       0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 300, 300, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 150, 150, 8)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 150, 150, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 75, 75, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 75, 75, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 37, 37, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 43808)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                1401888   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,408,118\n",
      "Trainable params: 1,408,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "for filter in filters:\n",
    "    for units in dense_units:\n",
    "        for function in functions:\n",
    "            # if counter < 25:\n",
    "            #     counter += 1\n",
    "            #     continue\n",
    "            model = function(img_height, img_width, num_classes, filter, 2, units)\n",
    "            model.compile(optimizer='Adam',\n",
    "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.summary()\n",
    "            history = model.fit(\n",
    "                train_ds,\n",
    "                validation_data=val_ds,\n",
    "                epochs=epochs\n",
    "            )\n",
    "\n",
    "            evaluation = model.evaluate(test_ds)\n",
    "            eval_results[f'model_{counter}'] = {\"train_accuracy\": history.history['accuracy'][-1],\n",
    "                                                 \"val_accuracy\": history.history['val_accuracy'][-1],\n",
    "                                                 \"test_loss\": evaluation[0], \"test_accuracy\": evaluation[1]}\n",
    "\n",
    "            if not os.path.exists('models/'):\n",
    "                os.makedirs('models')\n",
    "            model.save('models/model_' + str(counter))\n",
    "            with open('models/results.json', 'w') as out_file:\n",
    "                json.dump(eval_results, out_file)\n",
    "            print(f\"Progress: {counter}/{total}\")\n",
    "            counter += 1\n",
    "\n",
    "with open('models/results.json', 'w') as out_file:\n",
    "    json.dump(eval_results, out_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}