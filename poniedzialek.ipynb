{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from model import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(data_set, train_percent, val_percent, test_percent):\n",
    "    data_set = data_set.shuffle(buffer_size=len(data_set), reshuffle_each_iteration=False)\n",
    "\n",
    "    train_size = int(len(data_set) * train_percent)\n",
    "    val_size = int(len(data_set) * val_percent)\n",
    "    test_size = int(len(data_set) * test_percent)\n",
    "\n",
    "    train_ds = data_set.take(train_size)\n",
    "    val_ds = data_set.skip(train_size).take(val_size)\n",
    "    test_ds = data_set.skip(train_size + val_size).take(test_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def prepare_using_layers(ds, directory_name=\"augmented_dataset\", rot=False, bright=False, flip=False):\n",
    "    \"\"\"\n",
    "    Function augments given dataset using Sequential model layers\n",
    "    :param directory_name: name of a directory where augmented images will be saved\n",
    "    :param ds: dataset to be augmented\n",
    "    :param rot: determines whether to apply random rotation\n",
    "    :param bright: determines whether to apply random brightness\n",
    "    :param flip: determines whether to apply random flips\n",
    "    :return: augmented dataset\n",
    "    \"\"\"\n",
    "    batch, _ = next(iter(ds))\n",
    "    batch_size = batch.shape[0]\n",
    "    img_height = batch.shape[1]\n",
    "    img_width = batch.shape[2]\n",
    "\n",
    "    if not os.path.exists('datasets/' + directory_name):\n",
    "        os.makedirs('datasets/' + directory_name)\n",
    "    labels = ds.class_names\n",
    "    for label in labels:\n",
    "        if not os.path.exists(f'datasets/{directory_name}/{label}'):\n",
    "            os.makedirs(f'datasets/{directory_name}/{label}')\n",
    "    counter = 0\n",
    "    for image_batch, labels_batch in ds:\n",
    "        for image, label in zip(image_batch, labels_batch):\n",
    "            tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "            counter += 1\n",
    "    if rot:\n",
    "        random_rot = tf.keras.Sequential([\n",
    "            layers.RandomRotation(0.2),\n",
    "        ])\n",
    "        augmented_ds = ds.map(lambda x, y: (random_rot(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        for image_batch, labels_batch in augmented_ds:\n",
    "            for image, label in zip(image_batch, labels_batch):\n",
    "                tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "                counter += 1\n",
    "    if bright:\n",
    "        random_bright = tf.keras.layers.RandomBrightness(factor=0.2)\n",
    "        augmented_ds = ds.map(lambda x, y: (random_bright(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        for image_batch, labels_batch in augmented_ds:\n",
    "            for image, label in zip(image_batch, labels_batch):\n",
    "                tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "                counter += 1\n",
    "    if flip:\n",
    "        random_flip = tf.keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        ])\n",
    "        augmented_ds = ds.map(lambda x, y: (random_flip(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        for image_batch, labels_batch in augmented_ds:\n",
    "            for image, label in zip(image_batch, labels_batch):\n",
    "                tf.keras.preprocessing.image.save_img(f'datasets/{directory_name}/{labels[label]}/{counter}.png', image)\n",
    "                counter += 1\n",
    "\n",
    "    data_dir = 'datasets/' + directory_name\n",
    "    data = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        image_size=(img_height, img_width))\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"datasets/improved_gestures_dataset\"  # Remember to recreate or change the path to the actual dataset\n",
    "data_dir = path\n",
    "\n",
    "batch_size = 32\n",
    "# (Mystyk) Image size might be different, just a guess based on webcam repo\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width))\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# augmented_ds = prepare(data, shuffle=False, rot=True , rgb=True, brightness=False, saturation=True, hue=False)\n",
    "augmented_ds = prepare_using_layers(data, directory_name=\"gestures_dataset\", rot=True, bright=True, flip=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for image_batch, labels_batch in augmented_ds:\n",
    "    for image, label in zip(image_batch, labels_batch):\n",
    "        counter += 1\n",
    "print(counter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = split_data(augmented_ds, 0.70, 0.2, 0.1)\n",
    "\n",
    "class_names = data.class_names\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1. / 255)\n",
    "\n",
    "num_classes = len(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "functions = [create_model1, create_model2, create_model3, create_model4, create_model5]\n",
    "filters = [8, 16, 32]\n",
    "pool_size = [2, 4, 8]\n",
    "dense_units = [32, 64, 128, 256]\n",
    "counter = 1\n",
    "total = len(filters) * len(pool_size) * len(dense_units) * len(functions)\n",
    "eval_results = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for filter in filters:\n",
    "    for pool in pool_size:\n",
    "        for units in dense_units:\n",
    "            for function in functions:\n",
    "                model = function(img_height, img_width, num_classes, filter, pool, units)\n",
    "                model.compile(optimizer='Adam',\n",
    "                              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "                model.summary()\n",
    "                history = model.fit(\n",
    "                    train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=epochs\n",
    "                )\n",
    "\n",
    "                evaluation = model.evaluate(test_ds)\n",
    "                eval_results[f'model_{counter}'] = {\"train_accuracy\": history.history['accuracy'][-1],\n",
    "                                                     \"val_accuracy\": history.history['val_accuracy'][-1],\n",
    "                                                     \"test_loss\": evaluation[0], \"test_accuracy\": evaluation[1]}\n",
    "\n",
    "                if not os.path.exists('models/'):\n",
    "                    os.makedirs('models')\n",
    "                model.save('models/model_' + str(counter))\n",
    "                print(f\"Progress: {counter}/{total}\")\n",
    "                counter += 1\n",
    "\n",
    "with open('models/results.json', 'w') as out_file:\n",
    "    json.dump(eval_results, out_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}